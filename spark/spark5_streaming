Map Reduce can only be used in batch operations, but spark is realtime and you could do realtime operations
It is on top of spark engine.
Real time decisions and analytics, like credit card fraud detection, spam filtering,  click stream processing, network intrusion
  real time social media analytics, ad recommendation, stock market analytics
Spark helps you 
  Look at data as they are created/arrive from source
    - from flat files
    - tcp/ip messages
    - apache flume, take log files from multiple clients and serialize them
    - apache kafka, take various sources and marshall to pass the messages
    - amazon kinesis
    - social medias, rest api to listening
  Transform, summarize and analyze
  Perform ML 
  Predict in real time
  
  Spark Streaming Architecture
  Master Node
    Spark context create the Streaming Context, need to be created before anything,
    Set a Worker node as a receiver that will be listening to the source for getting data, receiving input by soruce
    
  Worker Node
    Long Tasks .. Receiver. Collect the data
    Task ........ Cache and Task that perform the operations in real time.
    
  DStreams
  Streaming context need to be set from Spark context to create the support for the Stream
  Discredited Stream is DStream on which processing occurs, link between Spark and Data source.
  Micro Batches windows is setup for the DStream, data ingest in the system is setting in batches
  The continuous stream becomes a micro batch series.
  Each micro-batch is an RDD
  Windows functions
    -Windows size multiple of interval
    -Sliding interval multiple of interval
    
    
var ssc =  new StreamingContext(sc, Seconds(1))
var rddQueue = new Queue[RDD[Int]]()
